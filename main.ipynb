{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sumarizador de texto\n",
    "\n",
    "Esse projeto tem como objetivo criar resumos para diversos textos selecionando sentenças ou palavras que melhor representem os textos pelo grupamento de seus embedings. Isso signifia que, para fazer o resumo em sentenças, cada sentença do document passará por um algoritimo de embeding que a transformará em um vetor; com todas as sentenças como vetores é possivel utilizar clustering ou pagerank, para através da similaridade das sentenças, encontrar algumas que passem a ideia geral do texto resumido.\n",
    "\n",
    "Esse tipo de sumarização é conhecido como sumarização extrativa e diversos mecanismos de embeding podem ser utilizados para traçar a seelhança entre as sentenças e ajudar no processo de extração. Alguns deles, que serão aborados nesse projeto sao: TF-IDF, CBow, Doc2Vec, LDA e Word2Vec.\n",
    "\n",
    "De forma a verificar a qualidade dos sumarios, se optou por utilizar a metrica Rouge, que calcula pelo numero de palavras em comum entre um sumario referencia e o sumario criado o F1 score, a precisão e o recall do summario. Sendo que quanto maior a precisão, maior o recall e maior o f1, melhor é o sumario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summario\n",
    "\n",
    "### [Abre o Corpus](#Open)\n",
    "\n",
    "### [Funções Relevantes](#Func)\n",
    "\n",
    "### [Sumariza em sentenças](#Sent)\n",
    "\n",
    "[TF-IDF](#tfidf)\n",
    "\n",
    "[CBow](#cbow)\n",
    "\n",
    "[Doc 2 Vec](#doc2vec)\n",
    "\n",
    "[LDA](#lda)\n",
    "\n",
    "### [Sumariza em palavras](#Word)\n",
    "\n",
    "[Word 2 Vec](#word2vec)\n",
    "\n",
    "### [Conclusão](#Conc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs do usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dados que serão estudados [\"cnn_stories_sample\", \"cnn_stories\"]\n",
    "corpus = \"cnn_stories_sample\"\n",
    "\n",
    "# Configurações para os filtros das palavras\n",
    "min_sent_size = 5\n",
    "use_stopwords = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports para tratamento de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pickle\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Imports para tratamento de texto\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words(\"english\")\n",
    "\n",
    "# Imports para algoritimos de vectorização\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "# Imports para algoritimos de ranqueamento\n",
    "import networkx as nx\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# Imports para verificação do sumario\n",
    "from rouge import Rouge\n",
    "rouge = Rouge()\n",
    "\n",
    "# Outros\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abre o Corpus\n",
    "<a id='Open'></a>\n",
    "\n",
    "Nessa seção o corpus selecionado será aberto, filtrado pela função preprocess e salvo em jasons e TXTs para evitar novas filtragens no futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionario de palavras que devem ser removidas/modificadas\n",
    "manual_conversions = {\"nt\":\"not\", \"ll\":\"will\", \"m\":\"am\", \"s\":\"TRASH\"}\n",
    "if use_stopwords:\n",
    "    manual_conversions.update({stopword:\"TRASH\" for stopword in stopwords})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que filtra as palavras de uma sentença do texto\n",
    "def preprocess(sent):\n",
    "    sent = re.sub(\"-LRB-|-RRB-\", \"\", sent, flags=re.DOTALL|re.MULTILINE)\n",
    "    sent = sent.lower()\n",
    "    sent = re.sub(r\"[^a-z0-9\\ ]\", \"\", sent, flags=re.DOTALL|re.MULTILINE)\n",
    "    sent = re.sub(r\"[0-9]+\", \"num\", sent, flags=re.DOTALL|re.MULTILINE)\n",
    "    sent = re.sub(r\" +(?= )\", \"\", sent, flags=re.DOTALL|re.MULTILINE).strip()\n",
    "    sent = sent.split(\" \")\n",
    "    sent = [manual_conversions[word] if word in manual_conversions.keys() else word for word in sent]\n",
    "    return [word for word in sent if word != \"TRASH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abre os dados do corpus selecionado e faz a filtragem\n",
    "sents = {}\n",
    "orig_text = {}\n",
    "highlights = {}\n",
    "available_stories = os.listdir(f\"./{corpus}\")\n",
    "for storie in available_stories:\n",
    "    with open(f\"./cnn_stories_sample/{storie}\", \"r\", encoding=\"utf-8\") as file:\n",
    "        file = file.read()\n",
    "    original_sents = re.sub(r\"\\n\\n\", \" \", file.split(\"@highlight\")[0], flags=re.DOTALL|re.MULTILINE).split(\" . \")\n",
    "    highlights_sents = re.sub(r\"\\n\\n*\", \" . \", \"\".join(file.split(\"@highlight\")[1:]), flags=re.DOTALL|re.MULTILINE)\n",
    "\n",
    "    # Guarda o texto original e os highlights\n",
    "    orig_text[storie] = original_sents\n",
    "    highlights[storie] = highlights_sents\n",
    "\n",
    "    # Guarda as sentenças préprocessadas\n",
    "    preprocessed_sent = [preprocess(original_sent) for original_sent in original_sents]\n",
    "    sents[storie] = [sent for sent in preprocessed_sent if len(sent) > min_sent_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva os dadods filtrados tokenizados e originais\n",
    "with open(\"storage/orig_sents.json\", \"w\") as file:\n",
    "    json.dump(orig_text, file)\n",
    "\n",
    "with open(\"storage/highlights.json\", \"w\") as file:\n",
    "    json.dump(highlights, file)\n",
    "\n",
    "sents_reference = {}\n",
    "i = 0\n",
    "with open('storage/all_sents.txt', 'w', encoding='utf8') as file:\n",
    "    \n",
    "    for text_id, text in sents.items():\n",
    "        sents_reference[text_id] = []\n",
    "        \n",
    "        for sentence in text:\n",
    "            file.write(\" \".join([tok for tok in sentence]) + \"\\n\")\n",
    "            sents_reference[text_id].append(i)\n",
    "            i += 1\n",
    "            \n",
    "with open(\"storage/sents_reference.json\", \"w\") as file:\n",
    "    json.dump(sents_reference, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Funções relevantes\n",
    "<a id='Func'></a>\n",
    "\n",
    "Nessa seção, algumas funções são criadas para evitar repetição de código em cada modelo de embeding um veez que as etapas de carregamento dos dados, clustering, pagerank, calculo de score rouge e salvamento dos sumarios é muito semelhante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "     \n",
    "    with open('storage/all_sents.txt', 'r', encoding='utf8') as file:\n",
    "        all_sents = [sent.split(\" \") for sent in file.read().split(\"\\n\")]\n",
    "    \n",
    "    with open(\"storage/sents_reference.json\", \"r\") as file:\n",
    "        sents_reference = json.load(file)\n",
    "        \n",
    "    with open(\"storage/orig_sents.json\", \"r\") as file:\n",
    "        orig_sents = json.load(file)    \n",
    "\n",
    "    with open(\"storage/highlights.json\", \"r\") as file:\n",
    "        highlights = json.load(file)\n",
    "        \n",
    "    return all_sents, sents_reference, orig_sents, highlights\n",
    "\n",
    "\n",
    "def find_most_relevant_cl(vecs, sents_reference, clusters=3, per_cluster_sent=1):\n",
    "    \n",
    "    best = {}\n",
    "    warned = False\n",
    "    for text_id in sents_reference.keys():\n",
    "    \n",
    "        # Pega os vetores da sentença desse texto\n",
    "        target_vecs = vecs[sents_reference[text_id][0]:sents_reference[text_id][-1]+1] \n",
    "\n",
    "        # Faz a clusterização dessas sentenças\n",
    "        kmeans_cbow = MiniBatchKMeans(n_clusters=3, random_state=42)\n",
    "        result = kmeans_cbow.fit_transform(target_vecs)\n",
    "        df = pd.DataFrame(result)\n",
    "\n",
    "        # Seleciona a sentença mais próxima de cada centro de cluster\n",
    "        this_best = []\n",
    "        for cluster_number in range(result.shape[1]):\n",
    "            result = df[kmeans_cbow.labels_ == cluster_number].sort_values(by=cluster_number).index.values[:per_cluster_sent]\n",
    "            if len(result) > 0:\n",
    "                \n",
    "                result = list(result)\n",
    "                while len(result) < per_cluster_sent:\n",
    "                    result.append(0)\n",
    "                    \n",
    "                this_best.append(result)\n",
    "                \n",
    "            elif not warned:\n",
    "                warned = True\n",
    "                warnings.warn(\"No center vector found in one of the clusters\", RuntimeWarning)\n",
    "                \n",
    "        best[text_id] = set(sorted(list(np.array(this_best).flatten())))\n",
    "            \n",
    "    return best\n",
    "\n",
    "def find_most_relevant_pr(vecs, sents_reference, n_sents=3, squared=False):\n",
    "\n",
    "    best = {}\n",
    "    for text_id in sents_reference.keys():\n",
    "\n",
    "        # Pega os vetores da sentença desse texto\n",
    "        target_vecs = vecs[sents_reference[text_id][0]:sents_reference[text_id][-1]+1] \n",
    "        target_vecs = [vec.toarray() for vec in target_vecs]\n",
    "        # Faz a clusterização dessas sentenças\n",
    "        sim_mat = np.zeros((len(sents_reference[text_id]), len(sents_reference[text_id])))\n",
    "        for i, v1 in enumerate(target_vecs):\n",
    "            for j, v2 in enumerate(target_vecs):\n",
    "                norm1 = np.linalg.norm(v1)\n",
    "                norm2 = np.linalg.norm(v2)\n",
    "                # Verifica se alguem vetor possui apenas zeros e Verifica se o valor da normalização é razoavel\n",
    "                if (v1.sum() != 0 and v2.sum() != 0) and ((norm1 + norm2) > np.finfo(float).eps):\n",
    "                    if squared:\n",
    "                        sim_mat[i][j] = ((v1 * v2).sum() / (norm1 + norm2)) ** 2\n",
    "                    else:\n",
    "                        sim_mat[i][j] = (v1 * v2).sum() / (norm1 + norm2)\n",
    "\n",
    "        graph = nx.from_numpy_array(sim_mat)\n",
    "        pr = nx.pagerank_numpy(graph)\n",
    "\n",
    "        best[text_id] = set(sorted(pr, key=pr.get)[:n_sents])\n",
    "        \n",
    "    return best\n",
    "\n",
    "def calculate_rouge(highlights, cl_predict, pr_predict):\n",
    "    \n",
    "    rouge_results = {}\n",
    "    for text_id in cl_predict.keys():\n",
    "        this_cl_summary = \" . \".join(cl_predict[text_id])\n",
    "        this_pr_summary = \" . \".join(pr_predict[text_id])\n",
    "        this_highlights = highlights[text_id]\n",
    "        \n",
    "        this_cl_summary = re.sub(r\"[^a-z0-9\\ ]\", \"\", this_cl_summary.lower(), flags=re.DOTALL|re.MULTILINE)\n",
    "        this_pr_summary = re.sub(r\"[^a-z0-9\\ ]\", \"\", this_pr_summary.lower(), flags=re.DOTALL|re.MULTILINE)\n",
    "        this_highlights = re.sub(r\"[^a-z0-9\\ ]\", \"\", this_highlights.lower(), flags=re.DOTALL|re.MULTILINE)\n",
    "        \n",
    "        cl_score = rouge.get_scores(this_cl_summary, this_highlights)\n",
    "        pr_score = rouge.get_scores(this_pr_summary, this_highlights)\n",
    "        \n",
    "        rouge_results[text_id] = {name:result for name, result in zip([\"Cluster\", \"PageRank\"], cl_score + pr_score)}\n",
    "        \n",
    "    return rouge_results\n",
    "\n",
    "def average_rouge(rouge_results):\n",
    "    \n",
    "    n_texts = len(rouge_results)\n",
    "\n",
    "    sample = np.array([0, 0, 0])\n",
    "    cl_results = {\"Rouge1\":sample,\"Rouge2\":sample,\"RougeL\":sample}\n",
    "    pr_results = {\"Rouge1\":sample,\"Rouge2\":sample,\"RougeL\":sample}\n",
    "\n",
    "    for text_id, score in rouge_results.items():\n",
    "        cl_results[\"Rouge1\"] = cl_results[\"Rouge1\"] + np.array(list(score[\"Cluster\"]['rouge-1'].values()))\n",
    "        cl_results[\"Rouge2\"] = cl_results[\"Rouge2\"] + np.array(list(score[\"Cluster\"]['rouge-2'].values()))\n",
    "        cl_results[\"RougeL\"] = cl_results[\"RougeL\"] + np.array(list(score[\"Cluster\"]['rouge-l'].values()))\n",
    "\n",
    "        pr_results[\"Rouge1\"] = pr_results[\"Rouge1\"] + np.array(list(score[\"PageRank\"]['rouge-1'].values()))\n",
    "        pr_results[\"Rouge2\"] = pr_results[\"Rouge2\"] + np.array(list(score[\"PageRank\"]['rouge-2'].values()))\n",
    "        pr_results[\"RougeL\"] = pr_results[\"RougeL\"] + np.array(list(score[\"PageRank\"]['rouge-l'].values()))\n",
    "\n",
    "    for key in cl_results.keys():\n",
    "        cl_results[key] = [round(i, 3) for i in cl_results[key]/n_texts]\n",
    "        pr_results[key] = [round(i, 3) for i in pr_results[key]/n_texts]\n",
    "    \n",
    "    return cl_results, pr_results\n",
    "\n",
    "def save_summary_result(model_name, summary_cl, summary_pr, rouge_results):\n",
    "    \n",
    "    if summary_cl != None:\n",
    "        with open(f\"outputs/summary_{model_name}_cl.json\", \"w\") as file:\n",
    "            json.dump(summary_cl, file)\n",
    "\n",
    "    if summary_pr != None:\n",
    "        with open(f\"outputs/summary_{model_name}_pr.json\", \"w\") as file:\n",
    "            json.dump(summary_pr, file)\n",
    "    \n",
    "    if rouge_results != None:\n",
    "        with open(f\"outputs/rouge_{model_name}.json\", \"w\") as file:\n",
    "            json.dump(rouge_results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumo com as sentenças\n",
    "<a id='Sent'></a>\n",
    "\n",
    "Nessa seção os modelos de embeding serão treinados no conjunto total de sentenças de todos os doumentos do corpus, em seguida serão utilizados para transformar as sentenças em vetores e esses vetores, dividos por documentos, passaram por algoritimos de clusterização e pagerank para terem suas sentenças mais relevantes selecionadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "<a id='tfidf'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sents, sents_reference, orig_text, highlights = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 666 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf = TfidfVectorizer(min_df=5, \n",
    "                        max_df=0.9, \n",
    "                        max_features=5000, \n",
    "                        sublinear_tf=False, \n",
    "                        analyzer=lambda x: x)\n",
    "\n",
    "tfidf_vecs = tfidf.fit_transform(all_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\NLP\\lib\\site-packages\\ipykernel_launcher.py:40: RuntimeWarning: No center vector found in one of the clusters\n"
     ]
    }
   ],
   "source": [
    "tfidf_cl_best = find_most_relevant_cl(tfidf_vecs, sents_reference)\n",
    "tfidf_cl_summary = {}\n",
    "for text_id in tfidf_cl_best.keys():\n",
    "    tfidf_cl_summary[text_id] = [orig_text[text_id][sent] for sent in tfidf_cl_best[text_id]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Page rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pr_best = find_most_relevant_pr(tfidf_vecs, sents_reference)\n",
    "tfidf_pr_summary = {}\n",
    "for text_id in tfidf_pr_best.keys():\n",
    "    tfidf_pr_summary[text_id] = [orig_text[text_id][sent] for sent in tfidf_pr_best[text_id]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faz o teste ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_rouge_results = calculate_rouge(highlights, tfidf_cl_summary, tfidf_pr_summary)\n",
    "tfidf_cl_score, tfidf_pr_score = average_rouge(tfidf_rouge_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results in order as: f, p, r\n",
      "Cluster  {'Rouge1': [0.238, 0.217, 0.292], 'Rouge2': [0.063, 0.057, 0.078], 'RougeL': [0.167, 0.154, 0.197]}\n",
      "PageRank {'Rouge1': [0.216, 0.189, 0.275], 'Rouge2': [0.049, 0.042, 0.065], 'RougeL': [0.144, 0.127, 0.178]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Results in order as: f, p, r\")\n",
    "print(\"Cluster \", tfidf_cl_score)\n",
    "print(\"PageRank\", tfidf_pr_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Olha um resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_id = list(tfidf_cl_summary.keys())[np.random.randint(0, len(tfidf_cl_summary))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"-LRB- CNN -RRB- -- Andy Murray 's first match since undergoing back surgery in September ended in a straight sets defeat to Jo-Wilfried Tsonga at an exhibition tournament in Abu Dhabi Thursday. The reigning Wimbledon champion went down 7-5 6-3 to the Frenchman , who himself was plagued by injury at the back end of this year. Murray , who has dropped to No. 4 in the rankings , lacked sharpness after his layoff and was broken in the 12th game of the opening set to fall behind. The British star has been training at his base in Florida to prepare for the upcoming season and looked set to even the match up when he gained an early break of service in the second set. But Tsonga hit back with two breaks of his own to wrap up victory in 72 minutes at the Zayed Sports City complex. `` The courts here are very fast and you have to react quickly , '' said 26-year-old Murray. `` Jo was sharper than me today , he served very well. `` It 's always good fun here. It 's great preparation for the season as you have to play against the best in the world. '' The organizers of the Mubadala World Tennis Championship have indeed attracted a stellar field with the top two ranked players , Rafael Nadal and Novak Djokovic , in the line-up. David Ferrer of Spain won the opening match Thursday as he beat Stanislas Wawrinka of Switzerland 7-5 6-1 to set up a semifinal clash against compatriot Nadal. Tsonga 's win over Murray has earned him a match against Serbia 's Djokovic , while Murray will gain much-needed match practice against Wawrinka in the fifth place playoff. Murray , recently voted BBC Sports Personality of the Year back in the UK , became the first British man to win the Wimbledon title in 77 years when he triumphed at the All England Club back in July , but his season took a turn for the worse as he became troubled by a long-standing back problem. \""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\". \".join(orig_text[text_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The reigning Wimbledon champion went down 7-5 6-3 to the Frenchman , who himself was plagued by injury at the back end of this year',\n",
       " \"`` It 's always good fun here\",\n",
       " \"'' The organizers of the Mubadala World Tennis Championship have indeed attracted a stellar field with the top two ranked players , Rafael Nadal and Novak Djokovic , in the line-up\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_cl_summary[text_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['`` Jo was sharper than me today , he served very well',\n",
       " \"`` It 's always good fun here\",\n",
       " 'But Tsonga hit back with two breaks of his own to wrap up victory in 72 minutes at the Zayed Sports City complex']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_pr_summary[text_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Cluster</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PageRank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>rouge-1</th>\n",
       "      <th>rouge-2</th>\n",
       "      <th>rouge-l</th>\n",
       "      <th>rouge-1</th>\n",
       "      <th>rouge-2</th>\n",
       "      <th>rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>0.267</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0.241</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.298</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cluster                 PageRank                \n",
       "  rouge-1 rouge-2 rouge-l  rouge-1 rouge-2 rouge-l\n",
       "f   0.267   0.097   0.222    0.209     0.0   0.128\n",
       "p   0.241   0.088   0.196    0.231     0.0   0.128\n",
       "r   0.298   0.109   0.256    0.191     0.0   0.128"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rouge = tfidf_rouge_results[text_id]\n",
    "\n",
    "reform = {(level1_key, level2_key): values\n",
    "          for level1_key, level2_dict in text_rouge.items()\n",
    "          for level2_key, values in level2_dict.items()}\n",
    "\n",
    "pd.DataFrame(reform).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_summary_result(\"tfidf\", tfidf_cl_summary, tfidf_pr_summary, tfidf_rouge_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW\n",
    "<a id='cbow'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sents, sents_reference, orig_text, highlights = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 35.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cbow = gensim.models.Word2Vec(\n",
    "    corpus_file='storage/all_sents.txt',\n",
    "    window=5,\n",
    "    size=200,\n",
    "    seed=42,\n",
    "    iter=100,\n",
    "    workers=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_word_vecs(model, sent):\n",
    "    vec = np.zeros(model.wv.vector_size)\n",
    "    for word in sent:\n",
    "        if word in model:\n",
    "            vec += model.wv.get_vector(word)\n",
    "            \n",
    "    norm = np.linalg.norm(vec)\n",
    "    if norm > np.finfo(float).eps:\n",
    "        vec /= norm\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_vecs = scipy.sparse.csr.csr_matrix([sum_word_vecs(cbow, sent) for sent in all_sents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\NLP\\lib\\site-packages\\ipykernel_launcher.py:40: RuntimeWarning: No center vector found in one of the clusters\n"
     ]
    }
   ],
   "source": [
    "cbow_cl_best = find_most_relevant_cl(cbow_vecs, sents_reference)\n",
    "cbow_cl_summary = {}\n",
    "for text_id in cbow_cl_best.keys():\n",
    "    cbow_cl_summary[text_id] = [orig_text[text_id][sent] for sent in cbow_cl_best[text_id]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Page rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\NLP\\lib\\site-packages\\networkx\\algorithms\\link_analysis\\pagerank_alg.py:335: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return dict(zip(G, map(float, largest / norm)))\n"
     ]
    }
   ],
   "source": [
    "cbow_pr_best = find_most_relevant_pr(cbow_vecs, sents_reference)\n",
    "cbow_pr_summary = {}\n",
    "for text_id in cbow_pr_best.keys():\n",
    "    cbow_pr_summary[text_id] = [orig_text[text_id][sent] for sent in cbow_pr_best[text_id]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faz o teste ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_rouge_results = calculate_rouge(highlights, cbow_cl_summary, cbow_pr_summary)\n",
    "cbow_cl_score, cbow_pr_score = average_rouge(cbow_rouge_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results in order as: f, p, r\n",
      "Cluster  {'Rouge1': [0.231, 0.209, 0.287], 'Rouge2': [0.056, 0.05, 0.07], 'RougeL': [0.16, 0.146, 0.191]}\n",
      "PageRank {'Rouge1': [0.219, 0.193, 0.273], 'Rouge2': [0.051, 0.044, 0.064], 'RougeL': [0.146, 0.13, 0.177]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Results in order as: f, p, r\")\n",
    "print(\"Cluster \", cbow_cl_score)\n",
    "print(\"PageRank\", cbow_pr_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Olha um resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_id = list(cbow_cl_summary.keys())[np.random.randint(0, len(cbow_cl_summary))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"-LRB- CNN -RRB- -- Didier Drogba scored the only goal as Chelsea beat Juventus 1-0 at Stamford Bridge to give Guus Hiddink 's side a slender advantage ahead of their Champions League last-16 second leg in Turin. Didier Drogba celebrates his goal as Chelsea took a narrow advantage after their home tie against Juventus. Drogba , his season hampered by injury , suspension and a fallout with axed coach Luiz Felipe Scolari , looked back to his predatory best when he took a pass from Salomon Kalou and despatched the ball beyond Gianluigi Buffon in the 12th minute. Former Chelsea coach Claudio Ranieri , now in charge of Juve , was given a warm reception by the home fans before the game. Ranieri is still held in high esteem by Chelsea supporters even though he failed to win a single trophy during his four-year stint at Stamford Bridge. Hiddink was taking charge of a Chelsea side at home for the first time since his temporary appointment and it was the hosts who made the first inroads towards goal with Jose Bosingwa forcing Buffon into a save with a left-foot shot from the edge of the area in the fourth minute. Four minutes later Drogba almost opened the scoring when he got ahead of his marker to turn a cross from Bosingwa just over the crossbar. But the Ivorian put the home side in front in the 12th minute when a superb through ball from Kalou provided him with a clear-cut shooting opportunity and Drogba supplied the required finish in style. It was the perfect start for the Premier League side although Juventus claimed Drogba was offside before he fired the ball home from 10 yards. In the 15th minute , Drogba should have made it two when he met a corner from Frank Lampard inside the six-yard box , but he inexplicably headed wide. Juventus enjoyed plenty of possession after the interval but found the Chelsea defense in fine form , with Petr Cech only having to deal with a succession of long-range efforts. Marco Marchionni and Alessandro del Piero both tried their luck from distance and Pavel Nedved went close near the end for the visitors. Chelsea also had chances to double their lead , notably when a 20-yard effort from Nicolas Anelka flashed inches wide , but Chelsea held on for the victory. `` We maybe should have scored a second goal to give us some breathing space for the second leg. I felt we suffered a little bit in the second half and Juventus are a difficult side to play , but I 'm happy with the result , '' Hiddink told Sky Sports. \""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\". \".join(orig_text[text_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In the 15th minute , Drogba should have made it two when he met a corner from Frank Lampard inside the six-yard box , but he inexplicably headed wide',\n",
       " 'Juventus enjoyed plenty of possession after the interval but found the Chelsea defense in fine form , with Petr Cech only having to deal with a succession of long-range efforts']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_cl_summary[text_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Juventus enjoyed plenty of possession after the interval but found the Chelsea defense in fine form , with Petr Cech only having to deal with a succession of long-range efforts',\n",
       " 'Marco Marchionni and Alessandro del Piero both tried their luck from distance and Pavel Nedved went close near the end for the visitors',\n",
       " 'Ranieri is still held in high esteem by Chelsea supporters even though he failed to win a single trophy during his four-year stint at Stamford Bridge']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_pr_summary[text_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Cluster</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PageRank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>rouge-1</th>\n",
       "      <th>rouge-2</th>\n",
       "      <th>rouge-l</th>\n",
       "      <th>rouge-1</th>\n",
       "      <th>rouge-2</th>\n",
       "      <th>rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>0.274</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0.232</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.333</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cluster                 PageRank                \n",
       "  rouge-1 rouge-2 rouge-l  rouge-1 rouge-2 rouge-l\n",
       "f   0.274   0.022   0.146    0.205     0.0   0.097\n",
       "p   0.232   0.018   0.128    0.154     0.0   0.074\n",
       "r   0.333   0.026   0.171    0.308     0.0   0.143"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rouge = cbow_rouge_results[text_id]\n",
    "\n",
    "reform = {(level1_key, level2_key): values\n",
    "          for level1_key, level2_dict in text_rouge.items()\n",
    "          for level2_key, values in level2_dict.items()}\n",
    "\n",
    "pd.DataFrame(reform).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_summary_result(\"cbow\", cbow_cl_summary, cbow_pr_summary, cbow_rouge_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec\n",
    "<a id='doc2vec'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sents, sents_reference, orig_text, highlights = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec = gensim.models.Doc2Vec(\n",
    "    corpus_file='storage/all_sents.txt',\n",
    "    vector_size=200,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    workers=12,\n",
    "    epochs=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_vecs = scipy.sparse.csr.csr_matrix(doc2vec.docvecs.vectors_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\NLP\\lib\\site-packages\\ipykernel_launcher.py:40: RuntimeWarning: No center vector found in one of the clusters\n"
     ]
    }
   ],
   "source": [
    "doc2vec_cl_best = find_most_relevant_cl(doc2vec_vecs, sents_reference)\n",
    "doc2vec_cl_summary = {}\n",
    "for text_id in doc2vec_cl_best.keys():\n",
    "    doc2vec_cl_summary[text_id] = [orig_text[text_id][sent] for sent in doc2vec_cl_best[text_id]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Page rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_pr_best = find_most_relevant_pr(doc2vec_vecs, sents_reference)\n",
    "doc2vec_pr_summary = {}\n",
    "for text_id in doc2vec_pr_best.keys():\n",
    "    doc2vec_pr_summary[text_id] = [orig_text[text_id][sent] for sent in doc2vec_pr_best[text_id]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faz o teste ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_rouge_results = calculate_rouge(highlights, doc2vec_cl_summary, doc2vec_pr_summary)\n",
    "doc2vec_cl_score, doc2vec_pr_score = average_rouge(doc2vec_rouge_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results in order as: f, p, r\n",
      "Cluster  {'Rouge1': [0.232, 0.206, 0.292], 'Rouge2': [0.057, 0.051, 0.073], 'RougeL': [0.161, 0.145, 0.195]}\n",
      "PageRank {'Rouge1': [0.233, 0.2, 0.301], 'Rouge2': [0.06, 0.051, 0.079], 'RougeL': [0.155, 0.135, 0.193]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Results in order as: f, p, r\")\n",
    "print(\"Cluster \", doc2vec_cl_score)\n",
    "print(\"PageRank\", doc2vec_pr_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Olha um resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_id = list(doc2vec_cl_summary.keys())[np.random.randint(0, len(doc2vec_cl_summary))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Tripoli , Libya -LRB- CNN -RRB- -- The head of Libya 's opposition government told reporters Saturday he welcomed a call Friday by Russian President Dmitry Medvedev for Moammar Gadhafi to step down. Medvedev 's statement , echoing the stance of American and European leaders , appeared to indicate a closing diplomatic window for the longtime Libyan strongman. The chairman of the National Transitional Council , Mustafa Abdul Jalil , said he has offered amnesty to Gadhafi loyalists who defect before the demise of the regime , but reiterated that there will be `` no negotiation for any solution until Gadhafi 's departure. '' Once that happens , elections and a constitutional referendum will be held within a year , Jailil said in the opposition stronghold of Benghazi. In an interview with CNN , Jalil said the council had sold a shipment of oil to China for $ 160 million. The confirmation of the sale is expected to buttress the political and economic credibility of the fledgling rebel power. The leader said the movement has a `` financial crisis '' and is seeking loans from outside the country. The council is happy for political support , but will not ask Russia for arms or economic aid , Jalil said. The unrest in Libya has persisted for months as opposition members demand an end to Gadhafi 's nearly 42-year rule. Jalil marked the 100th day of the nation 's civil war. `` We see victories emerging at both national and international levels , '' he said. `` We should celebrate what our heroic sons have accomplished in Misrata and the Nafusa mountains , as well as applaud the wide international support for our revolution. '' Meanwhile , a series of morning explosions rocked the capital of Tripoli on Saturday , including blasts at a compound belonging to Gadhafi and one at a nearby tribal compound , a government official said. The official said one morning strike occurred on Bab bin Ghashir , a tribal compound near Gadhafi 's Bab al-Aziziya compound , where the other strikes occurred. The official believed the strikes were NATO attacks. No casualties were reported. Morning strikes in Tripoli are rare. NATO confirmed one of the attacks -- a press officer said the strike on Bab bin Ghashir was timed to minimize civilian casualties. NATO said it targeted a vehicle storage area at Bab bin Ghashir. The tribal compound is used by people who volunteer as support forces for Libyan authorities. A decade ago , the site was used as a military station. NATO is operating under a U.N. Security Council resolution authorizing the use of any means -- with the exception of foreign occupation -- to protect civilians from attack or the threat of attack. It has been conducting airstrikes targeting Gadhafi 's military resources. CNN 's Amir Ahmed , Raja Razek , Nima Elbagir and Ben Wedeman contributed to this report. \""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\". \".join(orig_text[text_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['`` We should celebrate what our heroic sons have accomplished in Misrata and the Nafusa mountains , as well as applaud the wide international support for our revolution',\n",
       " 'A decade ago , the site was used as a military station']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_cl_summary[text_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A decade ago , the site was used as a military station',\n",
       " \"Tripoli , Libya -LRB- CNN -RRB- -- The head of Libya 's opposition government told reporters Saturday he welcomed a call Friday by Russian President Dmitry Medvedev for Moammar Gadhafi to step down\",\n",
       " \"Jalil marked the 100th day of the nation 's civil war\"]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_pr_summary[text_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlights[text_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Cluster</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PageRank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>rouge-1</th>\n",
       "      <th>rouge-2</th>\n",
       "      <th>rouge-l</th>\n",
       "      <th>rouge-1</th>\n",
       "      <th>rouge-2</th>\n",
       "      <th>rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>0.078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0.081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cluster                 PageRank                \n",
       "  rouge-1 rouge-2 rouge-l  rouge-1 rouge-2 rouge-l\n",
       "f   0.078     0.0   0.062    0.108     0.0   0.051\n",
       "p   0.081     0.0   0.065    0.094     0.0   0.044\n",
       "r   0.075     0.0   0.061    0.125     0.0   0.061"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rouge = doc2vec_rouge_results[text_id]\n",
    "\n",
    "reform = {(level1_key, level2_key): values\n",
    "          for level1_key, level2_dict in text_rouge.items()\n",
    "          for level2_key, values in level2_dict.items()}\n",
    "\n",
    "pd.DataFrame(reform).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_summary_result(\"doc2vec\", doc2vec_cl_summary, doc2vec_pr_summary, doc2vec_rouge_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA\n",
    "<a id='lda'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sents, sents_reference, orig_text, highlights = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(all_sents)\n",
    "doc2bow = [dictionary.doc2bow(sent) for sent in all_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "NUM_TOPICS = 20\n",
    "ldamodel = LdaMulticore(doc2bow, num_topics=NUM_TOPICS, id2word=dictionary, passes=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso se queira explorar a LDA mudar para True\n",
    "if False:\n",
    "    lda_display = pyLDAvis.gensim.prepare(ldamodel, doc2bow, dictionary, sort_topics=False)\n",
    "    pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_vecs = [ldamodel.get_document_topics(text) for text in doc2bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_vecs = []\n",
    "for vec in raw_vecs:\n",
    "    this_vec = []\n",
    "    curr = 0\n",
    "    for i in range(NUM_TOPICS):\n",
    "        if (i == vec[curr][0]):\n",
    "            this_vec.append(vec[curr][1])\n",
    "            curr+=1\n",
    "            if curr == len(vec):\n",
    "                curr = -1\n",
    "        else:\n",
    "            this_vec.append(0)\n",
    "    lda_vecs.append(this_vec)\n",
    "    \n",
    "lda_vecs = scipy.sparse.csr.csr_matrix(lda_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\NLP\\lib\\site-packages\\ipykernel_launcher.py:40: RuntimeWarning: No center vector found in one of the clusters\n"
     ]
    }
   ],
   "source": [
    "lda_cl_best = find_most_relevant_cl(lda_vecs, sents_reference)\n",
    "lda_cl_summary = {}\n",
    "for text_id in lda_cl_best.keys():\n",
    "    lda_cl_summary[text_id] = [orig_text[text_id][sent] for sent in lda_cl_best[text_id]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Page rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_pr_best = find_most_relevant_pr(lda_vecs, sents_reference)\n",
    "lda_pr_summary = {}\n",
    "for text_id in lda_pr_best.keys():\n",
    "    lda_pr_summary[text_id] = [orig_text[text_id][sent] for sent in lda_pr_best[text_id]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faz o teste ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_rouge_results = calculate_rouge(highlights, lda_cl_summary, lda_pr_summary)\n",
    "lda_cl_score, lda_pr_score = average_rouge(lda_rouge_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results in order as: f, p, r\n",
      "Cluster  {'Rouge1': [0.232, 0.207, 0.291], 'Rouge2': [0.058, 0.052, 0.074], 'RougeL': [0.162, 0.147, 0.197]}\n",
      "PageRank {'Rouge1': [0.227, 0.198, 0.292], 'Rouge2': [0.055, 0.047, 0.072], 'RougeL': [0.152, 0.134, 0.19]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Results in order as: f, p, r\")\n",
    "print(\"Cluster \", lda_cl_score)\n",
    "print(\"PageRank\", lda_pr_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Olha um resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_id = list(lda_cl_summary.keys())[np.random.randint(0, len(lda_cl_summary))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Rome -LRB- CNN -RRB- -- A cardinal from the Philippines , another from Austria and an archbishop from Ireland would be the `` least worst '' choices to be the next pope , according to a group representing the victims of abuse by priests. The Survivors Network of Those Abused by Priests , or SNAP , released its list Thursday as cardinals held meetings at the Vatican in a prelude to the selection of the next pontiff. The three are Cardinal Luis Tagle of the Philippines ; Cardinal Christoph Schoenborn of Austria ; and Archbishop Diarmuid Martin of Dublin , Ireland. Martin is not a cardinal , but SNAP noted that a man need not be a cardinal to be elected pope. Historically , the role has gone to cardinals , however. CNN Vatican analyst John Allen , also a correspondent for National Catholic Reporter , wrote last month that Schoenborn `` certainly has the right pedigree for the job. '' And Tagle has `` been a leader in pushing the church in Asia to take an aggressive stance on clerical abuse , '' Allen said in a series he wrote on the papal contenders. Tagle would normally be considered too young for the role , but Benedict XVI 's almost unprecedented resignation might have changed the way the cardinals think , he said. Wednesday , SNAP named its `` Dirty Dozen '' list of men it judged would be the worst candidates for pope because of their handling of , or comments on , past allegations of child sex abuse against clergy. The scandal has shaken global confidence in the church in recent years. A Pew Research Center poll published Wednesday indicates that U.S. Catholics see it as the biggest issue the Vatican faces. Asked what they think is the most important problem , 34 % of the U.S. Catholics questioned mention sex abuse , pedophilia or some other reference to the scandal. No other problem garnered more than 10 % of the responses. A report for Italian news magazine Panorama on Thursday claims that the church hierarchy was alerted to the problem decades ago , in 1965 but buried the warnings. ` Absolutely key ' Since Monday , the gathered cardinals have been holding meetings , known as general congregations , to discuss the most serious questions facing the church. The last of the cardinals summoned to choose the next pope , Jean-Baptiste Pham Minh Man of Vietnam , arrived at the Vatican on Thursday. No date has been set for the conclave , or secret election , for the new pope , said the Rev. Federico Lombardi , a Vatican spokesman. But Cardinal Roger Mahony , the retired archbishop of Los Angeles , suggested that the announcement might not be far away in a tweet posted Thursday. `` Days of General Congregations reaching a conclusion. Setting of date for Conclave nearing. Mood of excitement prevails among Cardinals , '' he said. The 115 cardinal-electors -- those under the age of 80 who are eligible to vote for the new pontiff -- are taking time to prepare for what many see as their greatest responsibility. Although some may be wondering why it 's taking so long to set the date for the conclave , Lombardi pushed back against the idea that the cardinals were dragging their feet. The discussions they are having in the general congregations are a vital part of the process , he said , since once the conclave starts there wo n't be much time between votes for reflection or the exchange of ideas. The cardinals have to have all the information they need in order to make a mature , responsible judgment in the election , especially at a time when the church faces complex issues , he said. `` The preparation is absolutely key , '' Lombardi said. Celibacy for priests a hot issue , not just for church leaders U.S. cardinals muzzled ? Italian media reports Thursday focused on the Vatican 's move to end the news briefings held this week by American cardinals , amid concerns over leaks of confidential discussions among the cardinals. Sister Mary Ann Walsh , director of media relations for the U.S. Conference of Catholic Bishops , wrote in a blog post that the decision Wednesday came after a media report in Italian daily La Stampa , which gave details of who had said what. `` I compared the shutdown to the old Catholic school style of one kid talks and everyone stays after school , '' she wrote , saying a similar thing happened before the last conclave in 2005. `` We 'll continue briefings , but without cardinals , to help U.S. media especially cover this exciting moment in the church , '' Walsh added. It 's been a week since Benedict XVI became the first pontiff in six centuries to resign from the role. Popes usually serve until their death. With Easter around the corner , many inside the Catholic Church would like to see a new pontiff in place to lead ceremonies. Watch for the smoke : How is a new pope elected ? ` Mix and mingle ' All the cardinals , including those older than 80 , are entitled to take part in the closed-door general congregations. Lombardi said 152 cardinals met Thursday morning. A second meeting will take place in the afternoon , as the cardinals seek to pick up the pace before agreeing on the date for the conclave. Thursday morning 's business included reports on the financial state of the Holy See , Lombardi said. He named the cardinals who delivered the reports but did not reveal their contents. The cardinals could continue their meetings on Saturday , Lombardi added , but are unlikely to meet Sunday when Mass may be held. Interactive : A look at possible papal contenders Some of the discussions happen over coffee , as one Vatican spokesman revealed Monday , the first day of the general congregations. `` There 's a coffee break for about 30 minutes at a special buffet area in the front part of the audience hall , '' said the Rev. Thomas Rosica. `` Cardinals have an opportunity to go down and mix and mingle. '' `` They want to say what the next pope will hear , because he 's probably in that room , and they also want to alert the people who have n't spent so much time in Rome just what the situation really is here as they see it , '' Cardinal Francis George of Chicago said. The electors also want to go into the conclave with pretty clear ideas about whom to vote for , Cardinal Sean O'Malley of Boston said. They , too , have no interest in seeing it drag on , and there is no reason to believe that it will. The past 11 conclaves have lasted no longer than four days , the diocese of Providence , Rhode Island , wrote on its website. That was n't always the case. In the 13th century , the election of one pope took two years and nine months , the diocese said. Catholics grew so angry at the cardinals ' indecision from 1268 to 1271 , when Gregory X was elected , that they boarded them up in their chamber and tore off the roof to expose them to the elements. The fiasco led to the creation of the conclave and its precise protocol -- partly to expedite the process. What 's in a name ? Clues to be found in next pope 's moniker CNN 's Hada Messia , David Schechter , Jo Shelley and Ben Brumfield contributed to this report. \""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\". \".join(orig_text[text_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Historically , the role has gone to cardinals , however',\n",
       " 'But Cardinal Roger Mahony , the retired archbishop of Los Angeles , suggested that the announcement might not be far away in a tweet posted Thursday',\n",
       " \"Although some may be wondering why it 's taking so long to set the date for the conclave , Lombardi pushed back against the idea that the cardinals were dragging their feet\"]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_cl_summary[text_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Thursday morning 's business included reports on the financial state of the Holy See , Lombardi said\",\n",
       " 'Lombardi said 152 cardinals met Thursday morning',\n",
       " 'CNN Vatican analyst John Allen , also a correspondent for National Catholic Reporter , wrote last month that Schoenborn `` certainly has the right pedigree for the job']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_pr_summary[text_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Cluster</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PageRank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>rouge-1</th>\n",
       "      <th>rouge-2</th>\n",
       "      <th>rouge-l</th>\n",
       "      <th>rouge-1</th>\n",
       "      <th>rouge-2</th>\n",
       "      <th>rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>0.263</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0.191</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.419</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cluster                 PageRank                \n",
       "  rouge-1 rouge-2 rouge-l  rouge-1 rouge-2 rouge-l\n",
       "f   0.263   0.062   0.212    0.088     0.0   0.107\n",
       "p   0.191   0.045   0.158    0.067     0.0   0.085\n",
       "r   0.419   0.100   0.321    0.129     0.0   0.143"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_rouge = doc2vec_rouge_results[text_id]\n",
    "\n",
    "reform = {(level1_key, level2_key): values\n",
    "          for level1_key, level2_dict in text_rouge.items()\n",
    "          for level2_key, values in level2_dict.items()}\n",
    "\n",
    "pd.DataFrame(reform).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_summary_result(\"lda\", lda_cl_summary, lda_pr_summary, lda_rouge_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumo com palavras chave\n",
    "<a id='Word'></a>\n",
    "\n",
    "Nessa seção os modelos de embeding serão treinados no conjunto total de palavras de todos os doumentos do corpus, em seguida serão utilizados para transformar as palavras em vetores e esses vetores, dividos por documentos, passaram por algoritimos de clusterização e pagerank para terem suas palavras mais relevantes selecionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec\n",
    "<a id='word2vec'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sents, sents_reference, orig_text, highlights = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 40.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_word2vec = gensim.models.Word2Vec(\n",
    "    corpus_file='storage/all_sents.txt',\n",
    "    window=5,\n",
    "    size=200,\n",
    "    seed=42,\n",
    "    iter=100,\n",
    "    workers=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "word2vec_vecs = []\n",
    "words_reference = {}\n",
    "i = 0\n",
    "for text_id, sents in sents_reference.items():\n",
    "    words_reference[text_id] = []\n",
    "    for sent in sents:\n",
    "        for word in all_sents[sent]:\n",
    "            if word in model_word2vec:\n",
    "                all_words.append(word)\n",
    "                word2vec_vecs.append(model_word2vec.wv.get_vector(word))\n",
    "                words_reference[text_id].append(i)\n",
    "                i += 1\n",
    "                \n",
    "word2vec_vecs = scipy.sparse.csr.csr_matrix(word2vec_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\NLP\\lib\\site-packages\\ipykernel_launcher.py:46: RuntimeWarning: No center vector found in one of the clusters\n"
     ]
    }
   ],
   "source": [
    "word2vec_cl_best = find_most_relevant_cl(word2vec_vecs, words_reference, per_cluster_sent=5)\n",
    "word2vec_cl_summary = {}\n",
    "for text_id in word2vec_cl_best.keys():\n",
    "    word2vec_cl_summary[text_id] = [all_words[word] for word in word2vec_cl_best[text_id]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Page rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como o Page rank trabalha com iterações de multiplicação de matrix de dimensões de NxN (N sendo o numero de vetores \n",
    "# do documento) e, quando se trata de palavras, o numero de vetores aumenta muito para documentos longos, o page rank passa\n",
    "# a demorar um tempo execivo para o calulo sendo que sua utilização não é reomendade nesse caso\n",
    "if False:\n",
    "    word2vec_pr_best = find_most_relevant_pr(word2vec_vecs, words_reference, squared=True, n_sents=15)\n",
    "    word2vec_pr_summary = {}\n",
    "    for text_id in word2vec_pr_best.keys():\n",
    "        word2vec_pr_summary[text_id] = [all_words[word] for word in word2vec_pr_best[text_id]]\n",
    "else:\n",
    "    word2vec_pr_summary = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Olha um resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_id = list(word2vec_cl_summary.keys())[np.random.randint(0, len(word2vec_cl_summary))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"-LRB- CNN -RRB- -- So , Gary Oldman , tell us what you really think. In a raw interview with Playboy , the actor , 56 , railed against Hollywood `` dishonesty '' and double standards , said that Mel Gibson and Alec Baldwin have been victims of hypocrisy and asserted that not voting for `` 12 Years a Slave '' to win an Oscar meant `` you were a racist. '' Oh , and he does n't like the Golden Globes , helicopter parents or reality TV , either. Indeed , the `` Dark Knight '' actor , who 's starring in the forthcoming `` Dawn of the Planet of the Apes , '' pulled no punches when talking about pretty much anything. The conversation will appear in the magazine 's July/August issue. The Gibson and Baldwin affairs really angered him , he said , because he believes their accusers do n't exactly have clean hands themselves. `` I do n't know about Mel. He got drunk and said a few things , but we 've all said those things. We 're all f *** ing hypocrites , '' Oldman said. `` The policeman who arrested him has never used the word ` n ***** ' or ` that f *** ing Jew ' ? I 'm being brutally honest here. It 's the hypocrisy of it that drives me crazy. `` Mel Gibson is in a town that 's run by Jews and he said the wrong thing because he 's actually bitten the hand that I guess has fed him -- and does n't need to feed him anymore because he 's got enough dough , '' Oldman continued. `` But some Jewish guy in his office somewhere has n't turned and said , ` That f *** ing kraut ' or ` F *** those Germans , ' whatever it is ? We all hide and try to be so politically correct. That 's what gets me. It 's just the sheer hypocrisy of everyone. '' Other Oldman tidbits : On reality TV : `` The museum of social decay. '' On helicopter parents : `` There 's never any unsupervised play to develop skills or learn about hierarchy in a group or how to share. The kids honestly believe they are the center of the f *** ing universe. But then they get out into the real world and it 's like , 'S ** t , maybe it 's not all about me , ' and that leads to narcissism , depression and anxiety. '' On political correctness at the Oscars : `` At the Oscars , if you did n't vote for '12 Years a Slave ' you were a racist. '' On the Golden Globes : `` A meaningless event. ... It 's 90 nobodies having a wank. '' If Oldman is hard on Hollywood and its people , he 's equally critical of himself. Asked about `` Sid & Nancy , '' his breakthrough film , he said , `` I do n't like myself in the movie. '' Ditto with `` The Fifth Element '' and `` The Dark Knight. '' `` It was work , '' he said. -LRB- He did have kind things to say about the film `` Tinker Tailor Soldier Spy , '' Francis Ford Coppola and `` Harry Potter and the Prisoner of Azkaban '' director Alfonso Cuaron. -RRB- As the interview continued , Oldman -- who described his politics as `` libertarian '' -- recognized that he may have been a little too blunt. `` So this interview has gone very badly. You have to edit and cut half of what I 've said , because it 's going to make me sound like a bigot , '' he said at one point `` You 're not a bigot ? '' replied interviewer David Hochman. `` No , but I 'm defending all the wrong people , '' Oldman said. `` I 'm saying Mel 's all right. Alec 's a good guy. So how do I come across ? Angry ? '' `` Passionate , certainly , '' Hochman said. `` Readers will have to form their own opinions. '' `` It 's dishonesty that frustrates me most , '' Oldman said. `` I ca n't bear double standards. It gets under my skin more than anything. '' \""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\". \".join(orig_text[text_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cnn',\n",
       " 'birthplace',\n",
       " 'francis',\n",
       " 'churches',\n",
       " 'pope',\n",
       " 'far',\n",
       " 'church',\n",
       " 'francis',\n",
       " 'philippines',\n",
       " 'places',\n",
       " 'cnn',\n",
       " 'coming',\n",
       " 'num',\n",
       " 'power',\n",
       " 'centers']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_cl_summary[text_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_pr_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_summary_result(\"word2vec\", word2vec_cl_summary, word2vec_pr_summary, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões\n",
    "<a id='Conc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {\"TFIDF\":{\"Cluster\":tfidf_cl_score, \"PageRank\":tfidf_pr_score},\n",
    "               \"CBow\":{\"Cluster\":cbow_cl_score, \"PageRank\":cbow_pr_score},\n",
    "               \"Doc2Vec\":{\"Cluster\":doc2vec_cl_score, \"PageRank\":doc2vec_pr_score},\n",
    "               \"LDA\":{\"Cluster\":lda_cl_score, \"PageRank\":lda_pr_score}}\n",
    "\n",
    "reform = {(level1_key, level2_key, level3_key): values\n",
    "           for level1_key, level2_dict in all_results.items()\n",
    "           for level2_key, level3_dict in level2_dict.items()\n",
    "           for level3_key, values      in level3_dict.items()}\n",
    "\n",
    "all_results = pd.DataFrame(reform, index=[\"F1\", \"Precision\", \"Recall\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">TFIDF</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Cluster</th>\n",
       "      <th>Rouge1</th>\n",
       "      <td>0.238</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rouge2</th>\n",
       "      <td>0.063</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RougeL</th>\n",
       "      <td>0.167</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">PageRank</th>\n",
       "      <th>Rouge1</th>\n",
       "      <td>0.216</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rouge2</th>\n",
       "      <td>0.049</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RougeL</th>\n",
       "      <td>0.144</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">CBow</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Cluster</th>\n",
       "      <th>Rouge1</th>\n",
       "      <td>0.231</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rouge2</th>\n",
       "      <td>0.056</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RougeL</th>\n",
       "      <td>0.160</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">PageRank</th>\n",
       "      <th>Rouge1</th>\n",
       "      <td>0.219</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rouge2</th>\n",
       "      <td>0.051</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RougeL</th>\n",
       "      <td>0.146</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Doc2Vec</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Cluster</th>\n",
       "      <th>Rouge1</th>\n",
       "      <td>0.232</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rouge2</th>\n",
       "      <td>0.057</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RougeL</th>\n",
       "      <td>0.161</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">PageRank</th>\n",
       "      <th>Rouge1</th>\n",
       "      <td>0.233</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rouge2</th>\n",
       "      <td>0.060</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RougeL</th>\n",
       "      <td>0.155</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">LDA</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">Cluster</th>\n",
       "      <th>Rouge1</th>\n",
       "      <td>0.232</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rouge2</th>\n",
       "      <td>0.058</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RougeL</th>\n",
       "      <td>0.162</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">PageRank</th>\n",
       "      <th>Rouge1</th>\n",
       "      <td>0.227</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rouge2</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RougeL</th>\n",
       "      <td>0.152</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            F1  Precision  Recall\n",
       "TFIDF   Cluster  Rouge1  0.238      0.217   0.292\n",
       "                 Rouge2  0.063      0.057   0.078\n",
       "                 RougeL  0.167      0.154   0.197\n",
       "        PageRank Rouge1  0.216      0.189   0.275\n",
       "                 Rouge2  0.049      0.042   0.065\n",
       "                 RougeL  0.144      0.127   0.178\n",
       "CBow    Cluster  Rouge1  0.231      0.209   0.287\n",
       "                 Rouge2  0.056      0.050   0.070\n",
       "                 RougeL  0.160      0.146   0.191\n",
       "        PageRank Rouge1  0.219      0.193   0.273\n",
       "                 Rouge2  0.051      0.044   0.064\n",
       "                 RougeL  0.146      0.130   0.177\n",
       "Doc2Vec Cluster  Rouge1  0.232      0.206   0.292\n",
       "                 Rouge2  0.057      0.051   0.073\n",
       "                 RougeL  0.161      0.145   0.195\n",
       "        PageRank Rouge1  0.233      0.200   0.301\n",
       "                 Rouge2  0.060      0.051   0.079\n",
       "                 RougeL  0.155      0.135   0.193\n",
       "LDA     Cluster  Rouge1  0.232      0.207   0.291\n",
       "                 Rouge2  0.058      0.052   0.074\n",
       "                 RougeL  0.162      0.147   0.197\n",
       "        PageRank Rouge1  0.227      0.198   0.292\n",
       "                 Rouge2  0.055      0.047   0.072\n",
       "                 RougeL  0.152      0.134   0.190"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TFIDF</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Rouge1</th>\n",
       "      <td>0.238</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBow</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Rouge1</th>\n",
       "      <td>0.231</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Rouge1</th>\n",
       "      <td>0.232</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Doc2Vec</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Rouge1</th>\n",
       "      <td>0.232</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PageRank</th>\n",
       "      <th>Rouge1</th>\n",
       "      <td>0.233</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>Rouge1</th>\n",
       "      <td>0.227</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBow</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>Rouge1</th>\n",
       "      <td>0.219</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">TFIDF</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>Rouge1</th>\n",
       "      <td>0.216</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster</th>\n",
       "      <th>RougeL</th>\n",
       "      <td>0.167</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>RougeL</th>\n",
       "      <td>0.162</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBow</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>RougeL</th>\n",
       "      <td>0.160</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Doc2Vec</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>RougeL</th>\n",
       "      <td>0.161</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PageRank</th>\n",
       "      <th>RougeL</th>\n",
       "      <td>0.155</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>RougeL</th>\n",
       "      <td>0.152</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBow</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>RougeL</th>\n",
       "      <td>0.146</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">TFIDF</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>RougeL</th>\n",
       "      <td>0.144</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cluster</th>\n",
       "      <th>Rouge2</th>\n",
       "      <td>0.063</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Rouge2</th>\n",
       "      <td>0.058</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Doc2Vec</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Rouge2</th>\n",
       "      <td>0.057</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PageRank</th>\n",
       "      <th>Rouge2</th>\n",
       "      <td>0.060</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBow</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>Rouge2</th>\n",
       "      <td>0.056</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>Rouge2</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBow</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>Rouge2</th>\n",
       "      <td>0.051</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TFIDF</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>Rouge2</th>\n",
       "      <td>0.049</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            F1  Precision  Recall\n",
       "TFIDF   Cluster  Rouge1  0.238      0.217   0.292\n",
       "CBow    Cluster  Rouge1  0.231      0.209   0.287\n",
       "LDA     Cluster  Rouge1  0.232      0.207   0.291\n",
       "Doc2Vec Cluster  Rouge1  0.232      0.206   0.292\n",
       "        PageRank Rouge1  0.233      0.200   0.301\n",
       "LDA     PageRank Rouge1  0.227      0.198   0.292\n",
       "CBow    PageRank Rouge1  0.219      0.193   0.273\n",
       "TFIDF   PageRank Rouge1  0.216      0.189   0.275\n",
       "        Cluster  RougeL  0.167      0.154   0.197\n",
       "LDA     Cluster  RougeL  0.162      0.147   0.197\n",
       "CBow    Cluster  RougeL  0.160      0.146   0.191\n",
       "Doc2Vec Cluster  RougeL  0.161      0.145   0.195\n",
       "        PageRank RougeL  0.155      0.135   0.193\n",
       "LDA     PageRank RougeL  0.152      0.134   0.190\n",
       "CBow    PageRank RougeL  0.146      0.130   0.177\n",
       "TFIDF   PageRank RougeL  0.144      0.127   0.178\n",
       "        Cluster  Rouge2  0.063      0.057   0.078\n",
       "LDA     Cluster  Rouge2  0.058      0.052   0.074\n",
       "Doc2Vec Cluster  Rouge2  0.057      0.051   0.073\n",
       "        PageRank Rouge2  0.060      0.051   0.079\n",
       "CBow    Cluster  Rouge2  0.056      0.050   0.070\n",
       "LDA     PageRank Rouge2  0.055      0.047   0.072\n",
       "CBow    PageRank Rouge2  0.051      0.044   0.064\n",
       "TFIDF   PageRank Rouge2  0.049      0.042   0.065"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results.sort_values(\"Precision\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conlusão:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir dos scores rouge foi possivel observar que nenhum dos modelos obteve um sumario muito satisfatório, isso pode se dar:\n",
    "* Pela diferença de tamanho entre as sentenças selecionadas pelos algoritimos e pelo tamanho do highlight (as vezes mais palavras no highlight as vezes muitas palavras no summario) \n",
    "* O metodo de préprocessamento do texto, que ao rmover sentenças muito curtas e stopwords acabou atrapalhando o processo de rankeamento\n",
    "* A métrica rouge pode ser muito rigida para o tipo de teste realizado \n",
    "* A sumarização seja muito complexa para o nivel de desenvolvimento que foi feita para esses modelos\n",
    "\n",
    "De qualquer forma, pela validação manual foi possivel verifiar que alguns resumos ficaram razoaveis para o texto, apesar de não possuirem pontuações muito elevadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
