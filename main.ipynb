{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sumarizador de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from nltk import corpus as nltk_corpus\n",
    "from gensim.corpora import Dictionary\n",
    "from collections import defaultdict \n",
    "from rouge import Rouge \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pyLDAvis.gensim\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pickle\n",
    "import gensim\n",
    "import scipy\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "stopwords = nltk_corpus.stopwords.words(\"english\")\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs do usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select Corpus Number:\n",
      "0: NLTK Reunters\n",
      "1: NLTK Brown\n",
      "2: CNN\n",
      "3: CNN Sample\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 3\n"
     ]
    }
   ],
   "source": [
    "#[*NLTK corpus, \"sample_CNN\", \"CNN\"]\n",
    "\n",
    "def print_options(dct):\n",
    "    print (\"Select Corpus Number:\")\n",
    "    for item, value in dct.items():\n",
    "        print(f\"{item}: {value}\")\n",
    "\n",
    "_corpus = {\"0\": \"NLTK Reunters\",\n",
    "           \"1\": \"NLTK Brown\",\n",
    "           \"2\": \"CNN\",\n",
    "           \"3\": \"CNN Sample\"}\n",
    "\n",
    "print_options(_corpus)\n",
    "corpus = _corpus[input()]\n",
    "    \n",
    "min_sent_size = 5\n",
    "use_stopwords = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abre o Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_conversions = defaultdict(lambda: None)\n",
    "manual_conversions.update({\"nt\":\"not\", \"ll\":\"will\", \"m\":\"am\", \"s\":\"TRASH\"})\n",
    "\n",
    "if use_stopwords:\n",
    "    manual_conversions.update({stopword:\"TRASH\" for stopword in stopwords})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sent):\n",
    "    sent = re.sub(\"-LRB-|-RRB-\", \"\", sent, flags=re.DOTALL|re.MULTILINE)\n",
    "    sent = sent.lower()\n",
    "    sent = re.sub(r\"[^a-z0-9\\ ]\", \"\", sent, flags=re.DOTALL|re.MULTILINE)\n",
    "    sent = re.sub(r\"[0-9]+\", \"num\", sent, flags=re.DOTALL|re.MULTILINE)\n",
    "    sent = re.sub(r\" +(?= )\", \"\", sent, flags=re.DOTALL|re.MULTILINE).strip()\n",
    "    sent = sent.split(\" \")\n",
    "    \n",
    "    sent = [manual_conversions[word] if manual_conversions[word] else word for word in sent]\n",
    "    return [word for word in sent if word != \"TRASH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_(data):\n",
    "    file_ids = data.fileids()\n",
    "\n",
    "    sents     = {}\n",
    "    orig_text = {}\n",
    "\n",
    "    for storie in file_ids:\n",
    "        file_sents = data.raw(storie).split(\".\\n\") \n",
    "        \n",
    "        orig_text[storie] = file_sents\n",
    "        preprocessed_sent = [preprocess(sent) for sent in file_sents]\n",
    "        sents[storie]     = [sent for sent in preprocessed_sent if len(sent) > min_sent_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(_dir):\n",
    "    sents      = {}\n",
    "    orig_text  = {}\n",
    "    highlights = {}\n",
    "    available_stories = os.listdir(_dir)\n",
    "    \n",
    "    for storie in available_stories:\n",
    "        with open(f\"{_dir}/{storie}\", \"r\", encoding=\"utf-8\") as file:\n",
    "            file = file.read()\n",
    "        \n",
    "        original_sents   = re.sub(r\"\\n\\n\", \" \", file.split(\"@highlight\")[0], flags=re.DOTALL|re.MULTILINE).split(\" . \")\n",
    "        highlights_sents = re.sub(r\"\\n\\n*\", \" . \", \"\".join(file.split(\"@highlight\")[1:]), flags=re.DOTALL|re.MULTILINE).split(\" . \")\n",
    "\n",
    "        # Guarda o texto original e os hghlights\n",
    "        orig_text[storie]  = original_sents\n",
    "        highlights[storie] = highlights_sents\n",
    "        \n",
    "        # Guarda as sentenças préprocessadas\n",
    "        preprocessed_sent = [preprocess(original_sent) for original_sent in original_sents]\n",
    "        sents[storie]     = [sent for sent in preprocessed_sent if len(sent) > min_sent_size]\n",
    "    \n",
    "    return sents, orig_text, highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(corpus == \"NLTK Reunters\"):\n",
    "    sents, orig_text = nltk_(corpus.reuters)\n",
    "\n",
    "elif(corpus == \"NLTK Brown\"):\n",
    "    sents, orig_text = nltk_(corpus.brow)\n",
    "    \n",
    "elif(corpus == \"CNN\"):\n",
    "    sents, orig_text, highlights = cnn(\"./cnn_stories\")\n",
    "    \n",
    "elif(corpus == \"CNN Sample\"):\n",
    "    sents, orig_text, highlights = cnn(\"./cnn_stories_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"storage/orig_sents.json\", \"w\") as file:\n",
    "    json.dump(orig_text, file)\n",
    "\n",
    "if \"CNN\" in corpus:\n",
    "    with open(\"storage/highlights.json\", \"w\") as file:\n",
    "        json.dump(sents, file)\n",
    "\n",
    "sents_reference = {}    \n",
    "with open('storage/all_sents.txt', 'w', encoding='utf8') as file:\n",
    "    i = 0\n",
    "    for text_id, text in sents.items():\n",
    "        sents_reference[text_id] = []\n",
    "        \n",
    "        for sentence in text:\n",
    "            file.write(\" \".join([tok for tok in sentence]) + \"\\n\")\n",
    "            sents_reference[text_id].append(i)\n",
    "            i += 1\n",
    "            \n",
    "with open(\"storage/sents_reference.json\", \"w\") as file:\n",
    "    json.dump(sents_reference, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Funções relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def load_data(cnn=False):\n",
    "     \n",
    "    with open('storage/all_sents.txt', 'r', encoding='utf8') as file:\n",
    "        all_sents = [sent.split(\" \") for sent in file.read().split(\"\\n\")]\n",
    "    \n",
    "    with open(\"storage/sents_reference.json\", \"r\") as file:\n",
    "        sents_reference = json.load(file)\n",
    "        \n",
    "    with open(\"storage/orig_sents.json\", \"r\") as file:\n",
    "        orig_sents = json.load(file)\n",
    "    \n",
    "    if cnn:\n",
    "        with open(\"storage/highlights.json\", \"r\") as file:\n",
    "            highlights = json.load(file)\n",
    "    else:\n",
    "        highlights = None\n",
    "        \n",
    "    return all_sents, sents_reference, orig_sents, highlights\n",
    "\n",
    "\n",
    "def find_most_relevant_cl(vecs, sents_reference, clusters=3, per_cluster_sent=1):\n",
    "    \n",
    "    best = {}\n",
    "    for text_id in sents_reference.keys():\n",
    "    \n",
    "        # Pega os vetores da sentença desse texto\n",
    "        target_vecs = vecs[sents_reference[text_id][0]:sents_reference[text_id][-1]+1] \n",
    "\n",
    "        # Faz a clusterização dessas sentenças\n",
    "        kmeans_cbow = MiniBatchKMeans(n_clusters=3, random_state=42)\n",
    "        result = kmeans_cbow.fit_transform(target_vecs)\n",
    "        df = pd.DataFrame(result)\n",
    "\n",
    "        # Seleciona a sentença mais próxima de cada centro de cluster\n",
    "        this_best = []\n",
    "        for cluster_number in range(result.shape[1]):\n",
    "            this_best.append(df[kmeans_cbow.labels_ == cluster_number].sort_values(by=cluster_number).index.values[:per_cluster_sent])\n",
    "        \n",
    "        best[text_id] = sorted(list(np.array(this_best).flatten()))\n",
    "            \n",
    "    return best\n",
    "\n",
    "def find_most_relevant_pr(vecs, sents_reference, n_sents=3):\n",
    "\n",
    "    best = {}\n",
    "    for text_id in sents_reference.keys():\n",
    "\n",
    "        # Pega os vetores da sentença desse texto\n",
    "        target_vecs = vecs[sents_reference[text_id][0]:sents_reference[text_id][-1]+1] \n",
    "        target_vecs = [vec.toarray() for vec in target_vecs]\n",
    "        \n",
    "        # Faz a clusterização dessas sentenças\n",
    "        sim_mat = np.zeros((len(sents_reference[text_id]), len(sents_reference[text_id])))\n",
    "        for i, v1 in enumerate(target_vecs):\n",
    "            for j, v2 in enumerate(target_vecs):\n",
    "                norm1 = np.linalg.norm(v1)\n",
    "                norm2 = np.linalg.norm(v2)\n",
    "        \n",
    "                # Verifica se alguem vetor possui apenas zeros\n",
    "                if v1.sum() != 0 and v2.sum() != 0:\n",
    "                    \n",
    "                    # Verifica se o valor da normalização é razoavel\n",
    "                    if norm1 > np.finfo(float).eps and norm2 > np.finfo(float).eps:\n",
    "                        sim_mat[i][j] = (v1 * v2).sum() / (norm1 + norm2)\n",
    "                    \n",
    "                    else:\n",
    "                        sim_mat[i][j] = (v1 * v2).sum()\n",
    "\n",
    "        graph = nx.from_numpy_array(sim_mat)\n",
    "        pr = nx.pagerank(graph, max_iter=100)\n",
    "\n",
    "        best[text_id] = sorted(pr, key=pr.get)[:n_sents]\n",
    "        \n",
    "    return best\n",
    "\n",
    "def find_most_relevant_rougue(orig_text, n_sents=3):\n",
    "    best = {}\n",
    "    for text_id in sents_reference.keys():\n",
    "\n",
    "        # Pega as sentençãs do texto\n",
    "        sents = all_sents[sents_reference[text_id][0]:sents_reference[text_id][-1]+1] \n",
    "        sents = [\" \".join(sents) for sents in sents]\n",
    "        \n",
    "        #sim_mat = np.zeros((len(sents_reference[text_id]), len(sents_reference[text_id]))) \n",
    "        for i, s1 in enumerate(sents):\n",
    "            for j, s2 in enumerate(sents):\n",
    "                score = Rouge().get_scores(s1, s2)\n",
    "                break\n",
    "            break\n",
    "\n",
    "#rougue_best = find_most_relevant_rougue(orig_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sents, sents_reference, orig_text, highlights = load_data((\"CNN\" in corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TfidfVectorizer(min_df=5, \n",
    "                        max_df=0.9, \n",
    "                        max_features=5000, \n",
    "                        sublinear_tf=False, \n",
    "                        analyzer=lambda x: x)\n",
    "\n",
    "tfidf_vecs = model.fit_transform(all_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_cl_best = find_most_relevant_cl(tfidf_vecs, sents_reference)\n",
    "tfidf_cl_summary = {}\n",
    "for text_id in tfidf_cl_best.keys():\n",
    "    tfidf_cl_summary[text_id] = [orig_text[text_id][sent] for sent in tfidf_cl_best[text_id]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Page rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pr_best = find_most_relevant_pr(tfidf_vecs, sents_reference)\n",
    "tfidf_pr_summary = {}\n",
    "for text_id in tfidf_pr_best.keys():\n",
    "    tfidf_pr_summary[text_id] = [orig_text[text_id][sent] for sent in tfidf_pr_best[text_id]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Olha um resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_id = list(tfidf_cl_summary.keys())[np.random.randint(0, len(tfidf_cl_summary))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"-LRB- CNN -RRB- -- The worst kept secret in Formula One is finally out -- Fernando Alonso is leaving Ferrari and will be replaced by Sebastian Vettel. Red Bull 's four-time world champion has signed a three-year contract with the Scuderia , the oldest team in F1 , from 2015. After ending his five-year stint at Ferrari , Alonso remains coy on where he will be driving next season. The double move by two of the sport 's high profile world champions is the most significant in the driver market this season. But in the fickle world of F1 there are no guarantees it will work out for either of the ambitious racers. There are still seats to be filled at McLaren , Force India and Toro Rosso. With the curtain about to fall on the 2014 season at Sunday 's Abu Dhabi Grand Prix , hopeful drivers have just one more chance to stake their claim for the remaining seats. Where will Alonso go ? Alonso is regarded as the best all-round driver currently racing at the elite level of motorsport , a fact many of his peers are even happily willing to acknowledge. The Spaniard -- a double world champion with Renault in 2005 and 2006 -- is regarded as the key to the F1 driver market. The 33-year-old made it clear he wanted to leave Ferrari , even though he had two years left to run on his contract with the Italian team , but he has yet to confirm where he will go next. A return to McLaren seems most likely , despite his acrimonious departure from the team after just a single season as Lewis Hamilton 's teammate in 2007. McLaren is about to embark on a new phase after reigniting its relationship with engine manufacturer Honda. Alonso is expected to lead this new era at McLaren , although the fiercely ambitious driver may first want guarantees that the Honda engine is going to be a success. Keeping the media guessing about his future -- and maybe his future employers too -- seems to have provided Alonso with plenty of sport off track. Speculation in the media has seen Alonso linked with buying the Lotus team , joining forces with German sports car specialists Audi and even ousting Nico Rosberg or Hamilton at Mercedes. Alonso remained typically tight lipped about his future plans when he was questioned by the media at the Abu Dhabi season finale. Has Vettel made the right decision ? Vettel has endured his worst season at Red Bull in 2014 , failing to win a race compared to three victories for his rookie teammate Daniel Ricciardo. Since his full debut season for Toro Rosso in 2008 , the German has won at least one race a year , not to mention winning four straight world championships between 2010 and 2013. The 27-year-old is now hoping to succeed where Alonso failed at Ferrari by adding to his collection of world titles. `` The next stage of my Formula One career will be spent with Ferrari and for me that means the dream of a lifetime has come true , '' Vettel said. `` When I was a kid , Michael Schumacher in the red car was my greatest idol and now it 's an incredible honor to finally get the chance to drive a Ferrari. `` I am extremely motivated to help the team get back to the top. I will put my heart and soul into making it happen. '' Vettel will partner Kimi Raikkonen -- the last man to win a world title with Ferrari in 2007 -- in 2015 but there are no guarantees the car and its Ferrari engine will be any match for the might of Mercedes. Who will drive for McLaren ? McLaren has tried to dampen speculation over just who will be in its cars in 2015 in the build-up to this weekend 's season-ending race. `` We know you 're awaiting news on our driver line-up. We 'll announce after December 1 -- you 'll hear it here first , '' the team said on Twitter. Alonso remains the red-hot favorite to take one of the seats but the future of current drivers Jenson Button and Kevin Magnussen remains unclear. Button -- the 2009 world champion with Brawn Grand Prix which has since morphed into Mercedes -- has remained sanguine about his future and has even explored the idea of moving to sports car racing. Danish rookie Magnussen is fiercely passionate about staying with McLaren , the team which gave the 22-year-old his F1 debut in 2014. `` There is no Plan B , '' the Dane told CNN when asked if had explored his options if he was n't retained by the eight-time world champions. Which other teams have seats to fill ? Mercedes , Red Bull , Ferrari , Williams , Lotus and Sauber have all confirmed their driver pairings for 2015. There are still seats on offer at McLaren , Force India and Toro Rosso. Force India has already announced it will retain German Nico Hulkenberg for 2015 but Mexican Sergio Perez has not had his position with the team confirmed. There 's also only one seat up for grabs at Toro Rosso , who will blood 17-year-old Max Verstappen as the youngest F1 driver in history next season. Junior Red Bull driver Carlos Sainz Jr is in pole position for the second seat -- and the Spaniard has been named as a test driver for Red Bull at the end of season test in Abu Dhabi -- although Toro Rosso may still retain French racer Jean-Eric Vergne. Sauber announced Swede Marcus Ericsson and Brazilian Felipe Nasr as its 2015 drivers in November much to the chagrin of current driver Adrian Sutil , who believed he had a contract with the team for next season. Ericsson and Nasr are both pay drivers , backed by sponsors who bring an estimated $ 30m funding to the Swiss team. Grid shrinks to 18 in 2015 ? The F1 market may be flooded with plenty of eager racers but the number of seats has been squeezed. The financial pressures on the Caterham and Marussia teams , which both went into administration in October , means there are , in theory , only 18 spots on the F1 grid in 2015. After missing the U.S. and Brazil grands prix , Caterham has used crowdfunding to help finance a return in Abu Dhabi. Japan 's Kamui Kobayashi retained his drive while the team has also handed Briton and former tester Will Stevens his F1 debut. Both Caterham and Marussia remain on the official entry list for the 2015 season but their future is dependent on a hard winter drumming up funding to stay in the sport. With teams spending a minimum of $ 70m per season , employing a driver who offers pace , performance and a pot of personal talent is more important than ever for those teams for ca n't afford super-talents like Alonso. \""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\". \".join(orig_text[text_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Red Bull 's four-time world champion has signed a three-year contract with the Scuderia , the oldest team in F1 , from 2015\",\n",
       " 'There are still seats to be filled at McLaren , Force India and Toro Rosso',\n",
       " \"`` We know you 're awaiting news on our driver line-up\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_cl_summary[text_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Button -- the 2009 world champion with Brawn Grand Prix which has since morphed into Mercedes -- has remained sanguine about his future and has even explored the idea of moving to sports car racing',\n",
       " 'Grid shrinks to 18 in 2015 ? The F1 market may be flooded with plenty of eager racers but the number of seats has been squeezed',\n",
       " '`` I am extremely motivated to help the team get back to the top']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_pr_summary[text_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word_to_Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sents, sents_reference, orig_text, highlights = load_data((\"CNN\" in corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_cbow = gensim.models.Word2Vec(\n",
    "    corpus_file='storage/all_sents.txt',\n",
    "    window=5,\n",
    "    size=200,\n",
    "    seed=42,\n",
    "    iter=100,\n",
    "    workers=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_word_vecs(model, sent):\n",
    "    vec = np.zeros(model.wv.vector_size)\n",
    "    for word in sent:\n",
    "        if word in model:\n",
    "            vec += model.wv.get_vector(word)\n",
    "            \n",
    "    norm = np.linalg.norm(vec)\n",
    "    if norm > np.finfo(float).eps:\n",
    "        vec /= norm\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_vecs = scipy.sparse.csr.csr_matrix([sum_word_vecs(model_cbow, sent) for sent in all_sents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_cl_best = find_most_relevant_cl(word2vec_vecs, sents_reference)\n",
    "word2vec_cl_summary = {}\n",
    "for text_id in word2vec_cl_best.keys():\n",
    "    word2vec_cl_summary[text_id] = [orig_text[text_id][sent] for sent in word2vec_cl_best[text_id]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Page rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "PowerIterationFailedConvergence",
     "evalue": "(PowerIterationFailedConvergence(...), 'power iteration failed to converge within 100 iterations')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPowerIterationFailedConvergence\u001b[0m           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-f7f33c099b33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword2vec_pr_best\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_most_relevant_pr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword2vec_vecs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msents_reference\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mword2vec_pr_summary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword2vec_pr_best\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mword2vec_pr_summary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtext_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0morig_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtext_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword2vec_pr_best\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtext_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-4648de871b4d>\u001b[0m in \u001b[0;36mfind_most_relevant_pr\u001b[1;34m(vecs, sents_reference, n_sents)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_mat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpagerank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mbest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtext_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_sents\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-434>\u001b[0m in \u001b[0;36mpagerank\u001b[1;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\leo_v\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\networkx\\utils\\decorators.py\u001b[0m in \u001b[0;36m_not_implemented_for\u001b[1;34m(not_implement_for_func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNetworkXNotImplemented\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnot_implement_for_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_not_implemented_for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\leo_v\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\networkx\\algorithms\\link_analysis\\pagerank_alg.py\u001b[0m in \u001b[0;36mpagerank\u001b[1;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPowerIterationFailedConvergence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPowerIterationFailedConvergence\u001b[0m: (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 100 iterations')"
     ]
    }
   ],
   "source": [
    "word2vec_pr_best = find_most_relevant_pr(word2vec_vecs, sents_reference)\n",
    "word2vec_pr_summary = {}\n",
    "for text_id in word2vec_pr_best.keys():\n",
    "    word2vec_pr_summary[text_id] = [orig_text[text_id][sent] for sent in word2vec_pr_best[text_id]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Olha um resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_id = list(word2vec_cl_summary.keys())[np.random.randint(0, len(word2vec_cl_summary))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\". \".join(orig_text[text_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word2vec_cl_summary[text_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_pr_summary[text_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sents, sents_reference, orig_text, highlights = load_data((\"CNN\" in corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(all_sents)\n",
    "doc2bow = [dictionary.doc2bow(sent) for sent in all_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "NUM_TOPICS = 20\n",
    "ldamodel = LdaMulticore(doc2bow, num_topics=NUM_TOPICS, id2word=dictionary, passes=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso se queira explorar a LDA mudar para True\n",
    "if False:\n",
    "    lda_display = pyLDAvis.gensim.prepare(ldamodel, doc2bow, dictionary, sort_topics=False)\n",
    "    pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_vecs = [ldamodel.get_document_topics(text) for text in doc2bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_vecs = []\n",
    "for vec in raw_vecs:\n",
    "    this_vec = []\n",
    "    curr = 0\n",
    "    for i in range(NUM_TOPICS):\n",
    "        if (i == vec[curr][0]):\n",
    "            this_vec.append(vec[curr][1])\n",
    "            curr+=1\n",
    "            if curr == len(vec):\n",
    "                curr = -1\n",
    "        else:\n",
    "            this_vec.append(0)\n",
    "    lda_vecs.append(this_vec)\n",
    "    \n",
    "lda_vecs = scipy.sparse.csr.csr_matrix(lda_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_cl_best = find_most_relevant_cl(lda_vecs, sents_reference)\n",
    "lda_cl_summary = {}\n",
    "for text_id in lda_cl_best.keys():\n",
    "    lda_cl_summary[text_id] = [orig_text[text_id][sent] for sent in lda_cl_best[text_id]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Page rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_pr_best = find_most_relevant_pr(lda_vecs, sents_reference)\n",
    "lda_pr_summary = {}\n",
    "for text_id in lda_pr_best.keys():\n",
    "    lda_pr_summary[text_id] = [orig_text[text_id][sent] for sent in lda_pr_best[text_id]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Olha um resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_id = list(lda_cl_summary.keys())[np.random.randint(0, len(lda_cl_summary))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\". \".join(orig_text[text_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda_cl_summary[text_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_pr_summary[text_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rougue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
